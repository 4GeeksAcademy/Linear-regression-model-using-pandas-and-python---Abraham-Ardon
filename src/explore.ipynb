{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Explore here"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "   fips  TOT_POP    0-9  0-9 y/o % of total pop  19-Oct  \\\n",
                        "0  1001    55601   6787               12.206615    7637   \n",
                        "1  1003   218022  24757               11.355276   26913   \n",
                        "2  1005    24881   2732               10.980266    2960   \n",
                        "3  1007    22400   2456               10.964286    2596   \n",
                        "4  1009    57840   7095               12.266598    7570   \n",
                        "\n",
                        "   10-19 y/o % of total pop  20-29  20-29 y/o % of total pop  30-39  \\\n",
                        "0                 13.735364   6878                 12.370281   7089   \n",
                        "1                 12.344167  23579                 10.814964  25213   \n",
                        "2                 11.896628   3268                 13.134520   3201   \n",
                        "3                 11.589286   3029                 13.522321   3113   \n",
                        "4                 13.087828   6742                 11.656293   6884   \n",
                        "\n",
                        "   30-39 y/o % of total pop  ...  COPD_number  diabetes_prevalence  \\\n",
                        "0                 12.749771  ...         3644                 12.9   \n",
                        "1                 11.564429  ...        14692                 12.0   \n",
                        "2                 12.865239  ...         2373                 19.7   \n",
                        "3                 13.897321  ...         1789                 14.1   \n",
                        "4                 11.901798  ...         4661                 13.5   \n",
                        "\n",
                        "   diabetes_Lower 95% CI  diabetes_Upper 95% CI  diabetes_number  \\\n",
                        "0                   11.9                   13.8             5462   \n",
                        "1                   11.0                   13.1            20520   \n",
                        "2                   18.6                   20.6             3870   \n",
                        "3                   13.2                   14.9             2511   \n",
                        "4                   12.6                   14.5             6017   \n",
                        "\n",
                        "   CKD_prevalence  CKD_Lower 95% CI  CKD_Upper 95% CI  CKD_number  \\\n",
                        "0             3.1               2.9               3.3        1326   \n",
                        "1             3.2               3.0               3.5        5479   \n",
                        "2             4.5               4.2               4.8         887   \n",
                        "3             3.3               3.1               3.6         595   \n",
                        "4             3.4               3.2               3.7        1507   \n",
                        "\n",
                        "   Urban_rural_code  \n",
                        "0                 3  \n",
                        "1                 4  \n",
                        "2                 6  \n",
                        "3                 2  \n",
                        "4                 2  \n",
                        "\n",
                        "[5 rows x 108 columns]\n",
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 3140 entries, 0 to 3139\n",
                        "Columns: 108 entries, fips to Urban_rural_code\n",
                        "dtypes: float64(61), int64(45), object(2)\n",
                        "memory usage: 2.6+ MB\n",
                        "None\n"
                    ]
                }
            ],
            "source": [
                "# Your code here\n",
                "import pandas as pd\n",
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "\n",
                "url = \"https://raw.githubusercontent.com/4GeeksAcademy/regularized-linear-regression-project-tutorial/main/demographic_health_data.csv\"\n",
                "data = pd.read_csv(url)\n",
                "\n",
                "print(data.head())\n",
                "print(data.info())\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "fips                      0\n",
                        "TOT_POP                   0\n",
                        "0-9                       0\n",
                        "0-9 y/o % of total pop    0\n",
                        "19-Oct                    0\n",
                        "                         ..\n",
                        "CKD_prevalence            0\n",
                        "CKD_Lower 95% CI          0\n",
                        "CKD_Upper 95% CI          0\n",
                        "CKD_number                0\n",
                        "Urban_rural_code          0\n",
                        "Length: 108, dtype: int64\n",
                        "               fips       TOT_POP           0-9  0-9 y/o % of total pop  \\\n",
                        "count   3140.000000  3.140000e+03  3.140000e+03             3140.000000   \n",
                        "mean   30401.640764  1.041894e+05  1.274030e+04               11.871051   \n",
                        "std    15150.559265  3.335834e+05  4.180730e+04                2.124081   \n",
                        "min     1001.000000  8.800000e+01  0.000000e+00                0.000000   \n",
                        "25%    18180.500000  1.096325e+04  1.280500e+03               10.594639   \n",
                        "50%    29178.000000  2.580050e+04  3.057000e+03               11.802727   \n",
                        "75%    45081.500000  6.791300e+04  8.097000e+03               12.951840   \n",
                        "max    56045.000000  1.010552e+07  1.208253e+06               25.460677   \n",
                        "\n",
                        "             19-Oct  10-19 y/o % of total pop         20-29  \\\n",
                        "count  3.140000e+03               3140.000000  3.140000e+03   \n",
                        "mean   1.336798e+04                 12.694609  1.446933e+04   \n",
                        "std    4.228439e+04                  1.815044  4.957773e+04   \n",
                        "min    0.000000e+00                  0.000000  0.000000e+00   \n",
                        "25%    1.374500e+03                 11.674504  1.263750e+03   \n",
                        "50%    3.274000e+03                 12.687422  3.108000e+03   \n",
                        "75%    8.822250e+03                 13.659282  8.976250e+03   \n",
                        "max    1.239139e+06                 23.304372  1.557073e+06   \n",
                        "\n",
                        "       20-29 y/o % of total pop         30-39  30-39 y/o % of total pop  ...  \\\n",
                        "count               3140.000000  3.140000e+03               3140.000000  ...   \n",
                        "mean                  12.283979  1.391649e+04                 11.751535  ...   \n",
                        "std                    3.126297  4.899095e+04                  1.696599  ...   \n",
                        "min                    0.000000  1.100000e+01                  6.092789  ...   \n",
                        "25%                   10.496774  1.232750e+03                 10.689322  ...   \n",
                        "50%                   11.772649  3.000500e+03                 11.580861  ...   \n",
                        "75%                   13.182260  8.314250e+03                 12.639379  ...   \n",
                        "max                   37.570198  1.501844e+06                 22.225129  ...   \n",
                        "\n",
                        "         COPD_number  diabetes_prevalence  diabetes_Lower 95% CI  \\\n",
                        "count    3140.000000          3140.000000            3140.000000   \n",
                        "mean     5827.242357            13.073503              12.088089   \n",
                        "std     15720.551934             2.724351               2.622948   \n",
                        "min         7.000000             6.100000               5.500000   \n",
                        "25%       815.000000            11.200000              10.300000   \n",
                        "50%      1963.500000            12.800000              11.800000   \n",
                        "75%      4727.000000            14.800000              13.700000   \n",
                        "max    434075.000000            25.600000              24.200000   \n",
                        "\n",
                        "       diabetes_Upper 95% CI  diabetes_number  CKD_prevalence  \\\n",
                        "count            3140.000000      3140.000000     3140.000000   \n",
                        "mean               14.053726      9326.577707        3.446242   \n",
                        "std                 2.824828     29754.601185        0.568059   \n",
                        "min                 6.700000        11.000000        1.800000   \n",
                        "25%                12.100000      1187.750000        3.100000   \n",
                        "50%                13.800000      2743.000000        3.400000   \n",
                        "75%                15.900000      6679.250000        3.800000   \n",
                        "max                27.000000    952335.000000        6.200000   \n",
                        "\n",
                        "       CKD_Lower 95% CI  CKD_Upper 95% CI     CKD_number  Urban_rural_code  \n",
                        "count       3140.000000       3140.000000    3140.000000       3140.000000  \n",
                        "mean           3.207516          3.710478    2466.234076          4.635350  \n",
                        "std            0.527740          0.613069    7730.422067          1.510447  \n",
                        "min            1.700000          1.900000       3.000000          1.000000  \n",
                        "25%            2.900000          3.300000     314.750000          3.000000  \n",
                        "50%            3.200000          3.700000     718.000000          5.000000  \n",
                        "75%            3.500000          4.100000    1776.250000          6.000000  \n",
                        "max            5.800000          6.600000  237766.000000          6.000000  \n",
                        "\n",
                        "[8 rows x 106 columns]\n"
                    ]
                }
            ],
            "source": [
                "print(data.isnull().sum())\n",
                "print(data.describe())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [],
            "source": [
                "X = data.drop(columns=[\n",
                "    \"Obesity_prevalence\",  # target\n",
                "    \"STATE_NAME\",\n",
                "    \"COUNTY_NAME\",\n",
                "    \"Urban_rural_code\",\n",
                "    \"fips\",\n",
                "    \"STATE_FIPS\",\n",
                "    \"CNTY_FIPS\"\n",
                "])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [],
            "source": [
                "X = pd.get_dummies(X, drop_first=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "X = data.drop(columns=[\"Obesity_prevalence\"])\n",
                "y = data[\"Obesity_prevalence\"]\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "X = X.select_dtypes(include=[\"number\"]) "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Index([], dtype='object')\n"
                    ]
                }
            ],
            "source": [
                "print(X.select_dtypes(include=\"object\").columns)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ValueError",
                    "evalue": "could not convert string to float: 'Oceana'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
                        "\u001b[32m/tmp/ipykernel_3898/1879921443.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m sklearn.linear_model \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m sklearn.metrics \u001b[38;5;28;01mimport\u001b[39;00m r2_score\n\u001b[32m      3\u001b[39m \n\u001b[32m      4\u001b[39m lr = LinearRegression()\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m lr.fit(X_train, y_train)\n\u001b[32m      6\u001b[39m \n\u001b[32m      7\u001b[39m y_pred = lr.predict(X_test)\n\u001b[32m      8\u001b[39m print(\u001b[33m\"Linear Regression R²:\"\u001b[39m, r2_score(y_test, y_pred))\n",
                        "\u001b[32m~/.local/lib/python3.11/site-packages/sklearn/base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1359\u001b[39m                 skip_parameter_validation=(\n\u001b[32m   1360\u001b[39m                     prefer_skip_nested_validation \u001b[38;5;28;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1361\u001b[39m                 )\n\u001b[32m   1362\u001b[39m             ):\n\u001b[32m-> \u001b[39m\u001b[32m1363\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
                        "\u001b[32m~/.local/lib/python3.11/site-packages/sklearn/linear_model/_base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    614\u001b[39m         n_jobs_ = self.n_jobs\n\u001b[32m    615\u001b[39m \n\u001b[32m    616\u001b[39m         accept_sparse = \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m self.positive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[33m\"csr\"\u001b[39m, \u001b[33m\"csc\"\u001b[39m, \u001b[33m\"coo\"\u001b[39m]\n\u001b[32m    617\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m618\u001b[39m         X, y = validate_data(\n\u001b[32m    619\u001b[39m             self,\n\u001b[32m    620\u001b[39m             X,\n\u001b[32m    621\u001b[39m             y,\n",
                        "\u001b[32m~/.local/lib/python3.11/site-packages/sklearn/utils/validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2967\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"estimator\"\u001b[39m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m check_y_params:\n\u001b[32m   2968\u001b[39m                 check_y_params = {**default_check_params, **check_y_params}\n\u001b[32m   2969\u001b[39m             y = check_array(y, input_name=\u001b[33m\"y\"\u001b[39m, **check_y_params)\n\u001b[32m   2970\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2971\u001b[39m             X, y = check_X_y(X, y, **check_params)\n\u001b[32m   2972\u001b[39m         out = X, y\n\u001b[32m   2973\u001b[39m \n\u001b[32m   2974\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m check_params.get(\u001b[33m\"ensure_2d\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
                        "\u001b[32m~/.local/lib/python3.11/site-packages/sklearn/utils/validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1364\u001b[39m         )\n\u001b[32m   1365\u001b[39m \n\u001b[32m   1366\u001b[39m     ensure_all_finite = _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[32m   1367\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m1368\u001b[39m     X = check_array(\n\u001b[32m   1369\u001b[39m         X,\n\u001b[32m   1370\u001b[39m         accept_sparse=accept_sparse,\n\u001b[32m   1371\u001b[39m         accept_large_sparse=accept_large_sparse,\n",
                        "\u001b[32m~/.local/lib/python3.11/site-packages/sklearn/utils/validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1050\u001b[39m                         )\n\u001b[32m   1051\u001b[39m                     array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1052\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1053\u001b[39m                     array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n\u001b[32m-> \u001b[39m\u001b[32m1054\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1055\u001b[39m                 raise ValueError(\n\u001b[32m   1056\u001b[39m                     \u001b[33m\"Complex data not supported\\n{}\\n\"\u001b[39m.format(array)\n\u001b[32m   1057\u001b[39m                 ) from complex_warning\n",
                        "\u001b[32m~/.local/lib/python3.11/site-packages/sklearn/utils/_array_api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    753\u001b[39m         \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[32m    754\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    755\u001b[39m             array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    756\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m             array = numpy.asarray(array, order=order, dtype=dtype)\n\u001b[32m    758\u001b[39m \n\u001b[32m    759\u001b[39m         \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    760\u001b[39m         \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n",
                        "\u001b[32m~/.local/lib/python3.11/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m   2164\u001b[39m             )\n\u001b[32m   2165\u001b[39m         values = self._values\n\u001b[32m   2166\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2167\u001b[39m             \u001b[38;5;66;03m# Note: branch avoids `copy=None` for NumPy 1.x support\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2168\u001b[39m             arr = np.asarray(values, dtype=dtype)\n\u001b[32m   2169\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2170\u001b[39m             arr = np.array(values, dtype=dtype, copy=copy)\n\u001b[32m   2171\u001b[39m \n",
                        "\u001b[31mValueError\u001b[39m: could not convert string to float: 'Oceana'"
                    ]
                }
            ],
            "source": [
                "from sklearn.linear_model import LinearRegression\n",
                "from sklearn.metrics import r2_score\n",
                "\n",
                "lr = LinearRegression()\n",
                "lr.fit(X_train, y_train)\n",
                "\n",
                "y_pred = lr.predict(X_test)\n",
                "print(\"Linear Regression R²:\", r2_score(y_test, y_pred))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/vscode/.local/lib/python3.11/site-packages/sklearn/base.py:1363: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
                        "  return fit_method(estimator, *args, **kwargs)\n"
                    ]
                },
                {
                    "ename": "ValueError",
                    "evalue": "could not convert string to float: 'Oceana'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
                        "\u001b[32m/tmp/ipykernel_3898/3730695717.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      4\u001b[39m r2_scores = []\n\u001b[32m      5\u001b[39m \n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m alpha \u001b[38;5;28;01min\u001b[39;00m alphas:\n\u001b[32m      7\u001b[39m     lasso = Lasso(alpha=alpha)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     lasso.fit(X_train, y_train)\n\u001b[32m      9\u001b[39m     y_pred = lasso.predict(X_test)\n\u001b[32m     10\u001b[39m     r2_scores.append(r2_score(y_test, y_pred))\n\u001b[32m     11\u001b[39m \n",
                        "\u001b[32m~/.local/lib/python3.11/site-packages/sklearn/base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1359\u001b[39m                 skip_parameter_validation=(\n\u001b[32m   1360\u001b[39m                     prefer_skip_nested_validation \u001b[38;5;28;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1361\u001b[39m                 )\n\u001b[32m   1362\u001b[39m             ):\n\u001b[32m-> \u001b[39m\u001b[32m1363\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
                        "\u001b[32m~/.local/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight, check_input)\u001b[39m\n\u001b[32m    978\u001b[39m         \u001b[38;5;66;03m# We expect X and y to be float64 or float32 Fortran ordered arrays\u001b[39;00m\n\u001b[32m    979\u001b[39m         \u001b[38;5;66;03m# when bypassing checks\u001b[39;00m\n\u001b[32m    980\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m check_input:\n\u001b[32m    981\u001b[39m             X_copied = self.copy_X \u001b[38;5;28;01mand\u001b[39;00m self.fit_intercept\n\u001b[32m--> \u001b[39m\u001b[32m982\u001b[39m             X, y = validate_data(\n\u001b[32m    983\u001b[39m                 self,\n\u001b[32m    984\u001b[39m                 X,\n\u001b[32m    985\u001b[39m                 y,\n",
                        "\u001b[32m~/.local/lib/python3.11/site-packages/sklearn/utils/validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2967\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"estimator\"\u001b[39m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m check_y_params:\n\u001b[32m   2968\u001b[39m                 check_y_params = {**default_check_params, **check_y_params}\n\u001b[32m   2969\u001b[39m             y = check_array(y, input_name=\u001b[33m\"y\"\u001b[39m, **check_y_params)\n\u001b[32m   2970\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2971\u001b[39m             X, y = check_X_y(X, y, **check_params)\n\u001b[32m   2972\u001b[39m         out = X, y\n\u001b[32m   2973\u001b[39m \n\u001b[32m   2974\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m check_params.get(\u001b[33m\"ensure_2d\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
                        "\u001b[32m~/.local/lib/python3.11/site-packages/sklearn/utils/validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1364\u001b[39m         )\n\u001b[32m   1365\u001b[39m \n\u001b[32m   1366\u001b[39m     ensure_all_finite = _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[32m   1367\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m1368\u001b[39m     X = check_array(\n\u001b[32m   1369\u001b[39m         X,\n\u001b[32m   1370\u001b[39m         accept_sparse=accept_sparse,\n\u001b[32m   1371\u001b[39m         accept_large_sparse=accept_large_sparse,\n",
                        "\u001b[32m~/.local/lib/python3.11/site-packages/sklearn/utils/validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1050\u001b[39m                         )\n\u001b[32m   1051\u001b[39m                     array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1052\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1053\u001b[39m                     array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n\u001b[32m-> \u001b[39m\u001b[32m1054\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1055\u001b[39m                 raise ValueError(\n\u001b[32m   1056\u001b[39m                     \u001b[33m\"Complex data not supported\\n{}\\n\"\u001b[39m.format(array)\n\u001b[32m   1057\u001b[39m                 ) from complex_warning\n",
                        "\u001b[32m~/.local/lib/python3.11/site-packages/sklearn/utils/_array_api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    753\u001b[39m         \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[32m    754\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    755\u001b[39m             array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    756\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m             array = numpy.asarray(array, order=order, dtype=dtype)\n\u001b[32m    758\u001b[39m \n\u001b[32m    759\u001b[39m         \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    760\u001b[39m         \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n",
                        "\u001b[32m~/.local/lib/python3.11/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m   2164\u001b[39m             )\n\u001b[32m   2165\u001b[39m         values = self._values\n\u001b[32m   2166\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2167\u001b[39m             \u001b[38;5;66;03m# Note: branch avoids `copy=None` for NumPy 1.x support\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2168\u001b[39m             arr = np.asarray(values, dtype=dtype)\n\u001b[32m   2169\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2170\u001b[39m             arr = np.array(values, dtype=dtype, copy=copy)\n\u001b[32m   2171\u001b[39m \n",
                        "\u001b[31mValueError\u001b[39m: could not convert string to float: 'Oceana'"
                    ]
                }
            ],
            "source": [
                "from sklearn.linear_model import Lasso\n",
                "\n",
                "alphas = list(range(0, 21))\n",
                "r2_scores = []\n",
                "\n",
                "for alpha in alphas:\n",
                "    lasso = Lasso(alpha=alpha)\n",
                "    lasso.fit(X_train, y_train)\n",
                "    y_pred = lasso.predict(X_test)\n",
                "    r2_scores.append(r2_score(y_test, y_pred))\n",
                "\n",
                "\n",
                "plt.plot(alphas, r2_scores, marker=\"o\")\n",
                "plt.xlabel(\"Lasso Alpha\")\n",
                "plt.ylabel(\"R² Score\")\n",
                "plt.title(\"Lasso Regularization Effect on R²\")\n",
                "plt.grid(True)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# I'm sorry Ilyas, I honestly don't know how to fix the errors you see, I tried multiple things and I did not want to look for solutions."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.4"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
